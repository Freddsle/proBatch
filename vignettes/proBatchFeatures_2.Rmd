---
title: "proBatch"
author: |
  | Yuliya Burankova
  | Institute for Computational Systems Biology, University of Hamburg, Germany
date: "`r Sys.Date()`"
output: pdf_document
#output: html_document
bibliography: "references.bib"
csl: "nature-no-superscript.csl"
vignette: >
  %\VignetteIndexEntry{ProBatchFeatures: QFeatures-based pipelines with operation logging for proBatch}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
abstract: |
  This vignette describes how to use ProBatchFeatures inside ProBatch package.
toc: yes
toc_depth: 2
numbersections: true
editor_options:
  markdown:
    wrap: 72
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE, warning = FALSE, message = FALSE, fig.pos = "h",
    collapse = TRUE,
    comment = "#>",
    knitr.table.format = "simple"
)
```

```{r setup, include = FALSE}
chooseCRANmirror(graphics = FALSE, ind = 1)
options(tinytex.verbose = TRUE)
```

# 1. Overview

`ProBatchFeatures` is a small extension around **QFeatures**
[@QFeatures] that stores each processing stage (for example, raw → log →
normalization → BEC → …) as a new **assay**, and logs every step. It
keeps data compatible with **SummarizedExperiment**/**QFeatures**
functions, and enables quick benchmarking of chained pipelines.

This vignette shows:

1.  Creating a `ProBatchFeatures` object from matrix and from long
    table.
2.  Running a typical pipeline: NA filtering → log → normalization →
    ComBat.
3.  Inspecting the operation chain and structured log.
4.  Running a grid of pipelines for benchmarking.

# 2. Loading the data

## Loading the libraries

In this vignette, we use functions from `dplyr`, `tibble` , `ggplot2`
and other `tidyverse` package family to transform some data frames

```{r load_packages, message=FALSE}
require(dplyr)
require(tibble)
require(ggplot2)
library(plyr)
```

## Load and prepare example dataset

Here, as example, we will use the E.coli dataset, described in the
FedProt paper [@burankova2025privacy]:

```{r load_data}
library(proBatch)
data("example_ecoli_data", package = "proBatch")
```

The dataset contains data from 5 centers, which were analysed
separately. First, before proceed, we need to merge data from all
centers into one dataset.

```{r extract-data}
# Extract data
all_metadata <- example_ecoli_data$all_metadata
all_precursors <- example_ecoli_data$all_precursors
all_protein_groups <- example_ecoli_data$all_protein_groups
all_precursor_pg_match <- example_ecoli_data$all_precursor_pg_match

# Keep only essential
rm(example_ecoli_data)
gc()
```

# 2. Build `ProBatchFeatures` from a matrix

The dataset consist of two levels (peptides and protein groups), and
`all_precursor_pg_match` dataframe stores links between them. Here, we
use the ProBatchFeatures() constructor to create an object for the
peptide level data first:

```{r build-pbf-from-matrix}
# Build from LONG directly
pbf <- ProBatchFeatures(
    data_matrix = all_precursors, # matrix of peptide intensities (features x samples)
    sample_annotation = all_metadata, # data.frame of sample metadata
    sample_id_col = "Run", # column in metadata that matches sample IDs
    level = "peptide" # label this assay level as "peptide"
)

pbf # show basic info about the ProBatchFeatures object
```

Next, we add the protein-level data as a second assay in the same
ProBatchFeatures instance. We do this by creating a SummarizedExperiment
for the protein data and then adding it to pb via QFeatures
functionality. It’s important to use the same sample annotation for the
new assay to ensure column alignment:

```{r add-new-pbf-level}
# Add proteins as a new level and link via mapping
#    all_precursor_pg_match has columns: "Precursor.Id", "Protein.Ids"
pbf <- pb_add_level(
    object = pbf,
    from = "peptide::raw",
    new_matrix = all_protein_groups,
    to_level = "protein", # will name "protein::raw" by default
    mapping_df = all_precursor_pg_match,
    from_id = "Precursor.Id",
    to_id = "Protein.Ids",
    map_strategy = "as_is"
)

pbf
```

If a precursor/peptide maps to multiple protein groups, parameter
`map_strategy` is used to determine how to resolve multiple to-ids per
from-id. Can be 'first' or 'longest', and 'as_is' expects one-to-one in
mapping. First two rules ("first" or "longest") yield a single ProteinID
per peptide for the linking variable. Here we know that there are no
duplicates, so 'as_is' used.

```{r}
# Check
validObject(pbf) # should be TRUE
assayLink(pbf, "protein::raw") # verify link summary

# Keep only essential
rm(all_metadata, all_precursor_pg_match, all_precursors, all_protein_groups)
gc()
```

## Extract matrices from `pbf` object

It is possible to extract specific matrix from a ProBatchFeatures object using the assay name name:

```{r matr}
extracted_matrix <- pb_assay_matrix(
    pbf,
    assay = "peptide::raw"
)
# show
extracted_matrix[1:5, 1:5]
rm(extracted_matrix)
```

The assay can also be exctracted into "long" form. In this case, the `sample_id_col` needs to be specified:

```{r extract_to_long}
extracted_long <- pb_as_long(
    pbf,
    sample_id_col = "Run",
    pbf_name = "peptide::raw"
)

# show
extracted_long[1:3, ]
rm(extracted_long)
```

# 3. Running a typical processing pipeline

Now that we have the data loaded into a `ProBatchFeatures` object with
peptide and protein assays, we can demonstrate an example of typical preprocessing
pipeline. This pipeline will include filtering out low-quality features,
log~2~ transformation, and median normalization. 

## 3.1  Initial assessment of the raw data

First, let's have a look at the data before any processing. We will use several visualization functions from the proBatch package to inspect the proteins::raw assay. 

We will start by examining the intensities across samples by plotting the sample mean. Here, the `plot_sample_mean()` function illustrates global average vs. sample batch. This can be helpful to visualize the global quantitative pattern and to identify discrepancies within or between batches.

```{r}
# It's good practice to define colors for consistent plotting
# color_scheme <- RColorBrewer::brewer.pal(n = 5, name = "Dark2")
# names(color_scheme) <- unique(pbf$Center)

# Alternatively, colors can be defined using:
color_scheme <- sample_annotation_to_colors(
    pbf,
    sample_id_col = "Run",
    factor_columns = c("Lab", "Condition"),
    numeric_columns = NULL
)
```


```{r plot_mean, fig.show='hold', fig.widght=5, fig.height=3}
plot_sample_mean(
    pbf,
    sample_id_col = "Run",
    order_col = "Lab",
    batch_col = "Condition",
    color_by_batch = TRUE,
    color_scheme = color_scheme,
    base_size = 10,
    pbf_name = "protein::raw"
)
```

## 3.2 Log₂ Transformation

Proteomics data is typically log-transformed to stabilize variance and make the data distribution more symmetric, which benefits many statistical methods. We'll apply a log₂ transformation to our data.

```{r}
pbf <- log_transform_dm(
    pbf,
    log_base = 2, offset = 1,
    pbf_name = "protein::raw"
)

pbf <- log_transform_dm(
    pbf,
    log_base = 2, offset = 1,
    pbf_name = "peptide::raw"
)

pbf
```

Let's visualize the effect of the transformation by comparing the boxplots of the data before and after.

```{r plot_logmean, fig.show='hold', fig.widght=5, warning=FALSE}
p1 <- plot_boxplot(
    pbf,
    sample_id_col = "Run",
    order_col = "Run",
    batch_col = "Lab",
    color_by_batch = TRUE,
    color_scheme = color_scheme,
    base_size = 7,
    pbf_name = "peptide::log2_on_raw"
) +
    ggtitle("After Log2 Transformation, peptide level")

p2 <- plot_boxplot(
    pbf,
    sample_id_col = "Run",
    order_col = "Run",
    batch_col = "Lab",
    color_by_batch = TRUE,
    color_scheme = color_scheme,
    base_size = 7,
    pbf_name = "protein::log2_on_raw"
) +
    ggtitle("After log2 Transformation, protein level")

# Arrange plots vertically
gridExtra::grid.arrange(p1, p2, ncol = 1)
```

The "After" plot shows that the distributions are now more symmetric and the variances across samples are more comparable. However, the differences in medians between samples from different batches (labs) are still apparent.

## 3.3 Principal Component Analysis

Next, we'll perform a Principal Component Analysis (PCA) to get a high-level overview of the sample clustering. We expect to see a strong batch effect, where samples cluster by their center of origin ("Lab") rather than their biological condition ("Condition"). 

```{r plot_PCA, fig.show='hold', fig.width=8, fig.height=4}
pca1 <- plot_PCA(
    pbf,
    pbf_name = "protein::log2_on_raw",
    sample_id_col = "Run",
    color_scheme = color_scheme,
    color_by = "Lab",
    shape_by = "Condition",
    fill_the_missing = NULL,
    plot_title = "NA rows removed, protein, log2",
    base_size = 10, point_size = 3, point_alpha = 0.5
)

pca2 <- plot_PCA(
    pbf,
    pbf_name = "protein::log2_on_raw",
    sample_id_col = "Run",
    color_scheme = color_scheme,
    color_by = "Condition",
    shape_by = "Lab",
    fill_the_missing = -1, # default value
    plot_title = "NA replaced with -1, protein, log2",
    base_size = 10, point_size = 3, point_alpha = 0.5
)

gridExtra::grid.arrange(pca1, pca2, ncol = 2, nrow = 1)
```



As anticipated, the PCA plot clearly shows that the primary source of variation in the raw data is the Center, confirming a strong batch effect that we will need to address.

## 3.4 Filtering missing values

A common first step in preprocessing is to remove features that have too many missing values across samples. These are often low-abundance peptides / proteins that are unreliably detected and can interfere with downstream analysis. First, let's visualize the distribution of missing values.

Here, functions from QFeatures package can be used:

```{r nNA_calc}
# nNA returns a DataFrame with counts of NAs per feature/sample
na_counts <- pb_nNA(pbf)

# na_counts contains info about total number of NAs and % in the data:
na_counts[["nNA"]]
```

It is possble to check individual result for rows and columns for each assay:

```{r nNA_individual}
# what is available:
names(na_counts[["peptide::raw"]])

# check NAs per sample:
head(na_counts[["peptide::raw"]]$nNAcols)
```

It's possible to plot missing values using clustering methods or visualize it by its distribution across features. For example, this histogram shows that a large number of peptides have missing values in many samples and also batch-related patterns in the data are visible:

```{r, fig.show='hold', fig.width=10, fig.height=4}
plot_NA_heatmap(
    pbf,
    show_rownames = F, show_row_dend = F,
    color_by = "Lab"
)
```

Also, it is possible to plot multiple assays in one plot:

```{r, fig.show='hold', fig.width=10, fig.height=4}
plot_NA_heatmap(
    pbf,
    pbf_name = c("peptide::raw", "protein::raw"),
    show_rownames = F, show_row_dend = F,
    color_by = "Lab"
)
```

The intensity distribution of proteins / peptides with and without NAs and peptide / protein identification overlap can be plotted:

```{r, fig.show='hold', fig.width=10, fig.height=4}
plot_NA_density(
    pbf,
    pbf_name = c("peptide::log2_on_raw", "protein::log2_on_raw")
)
```

```{r, fig.show='hold', fig.width=10, fig.height=4}
plot_NA_frequency(
    pbf,
    pbf_name = c("peptide::raw", "protein::raw"),
    show_percent = T
)
```
On the last plot, especially on the peptide panel,  we also can see batch-related pattern, as there are 19/20 samples per batch.

Here we apply a simple missing-data filter: we require each features (in this case peptide) to be quantified in at least 20% of the samples (you can choose a threshold appropriate for your data):

```{r}
# for that QFeatures functionality can be used:
pbf <- pb_filterNA(
    pbf,
    inplace = TRUE, # replace current assay with filtered
    pNA = 0.75
)
pbf
```

After filtering, the ProBatchFeatures object pbf will have fewer features.


```{r, fig.show='hold', fig.width=10, fig.height=4}
plot_NA_heatmap(
    pbf,
    pbf_name = c("peptide::raw", "protein::raw"),
    show_rownames = F, show_row_dend = F,
    color_by = "Lab"
)
```

## 3.5 Median Normalization

To make the samples more comparable, we will apply median normalization. This simple yet effective method aligns the distributions of intensities by subtracting the median intensity from each sample.

```{r}
pbf <- pb_transform(
    object = pbf,
    from = "peptide::log2_on_raw",
    steps = "medianNorm"
)

pbf <- pb_transform(
    object = pbf,
    from = "protein::log2_on_raw",
    steps = "medianNorm"
)

pbf
```

Now let's compare the boxplots of the log-transformed data with the median-normalized data.

```{r}
plot_boxplot(
    pbf,
    sample_id_col = "Run",
    order_col = "Run",
    batch_col = "Lab",
    color_by_batch = TRUE,
    color_scheme = color_scheme,
    base_size = 7,
    pbf_name = c("protein::log2_on_raw", "protein::medianNorm_on_log2_on_raw"),
    plot_ncol = 1,
    plot_title = c(
        "Before Median Normalization, protein level",
        "After Median Normalization, protein level"
    )
)
```


The effect of median normalization is clear: the medians of all samples are now aligned at zero, making them directly comparable for downstream analysis.

## 3.6 Assessing the Processed Data
After our preprocessing pipeline (filtering → log₂ transform → median normalization), let's re-evaluate the data to see if we have improved its structure and reduced the unwanted technical variation.

### Principal Component Analysis (PCA)
We will repeat the PCA on the final processed assay. We hope to see that the influence of the Center (batch effect) is reduced and that biological variation is more prominent.

```{r}
plot <- plot_PCA(
    pbf,
    pbf_name = c("protein::log2_on_raw", "protein::medianNorm_on_log2_on_raw"),
    sample_id_col = "Run",
    color_scheme = color_scheme,
    color_by = "Lab",
    shape_by = "Condition",
    fill_the_missing = NULL,
    base_size = 10, point_size = 3, point_alpha = 0.5
)
```

The new PCA plots show small improvement, but the strong clustering by Lab is still visible

### Hierarchical Clustering
Hierarchical clustering provides another way to visualize the relationships between samples. We'll generate a dendrogram and color the sample labels by their center.

```{r, fig.show='hold', fig.width=18, fig.height=4}
plot_hierarchical_clustering(
    pbf,
    sample_id_col = "Run",
    label_font = 0.5,
    color_list = color_scheme
)
```

### Principal Variance Component Analysis (PVCA)
PVCA is a powerful method that quantifies the contribution of different known factors (like batch, condition, etc.) to the total variation in the data. We'll use it to see how much variance is explained by Center, instrument, and biological Condition before and after processing.

```{r, fig.show='hold', fig.width=8, fig.height=4}
plot_PVCA(
    pbf,
    pbf_name = c("protein::log2_on_raw", "protein::medianNorm_on_log2_on_raw"),
    sample_id_col = "Run",
    technical_factors = c("Lab"),
    biological_factors = c("Condition"),
    fill_the_missing = NULL
)
```

The PVCA plot provides a quantitative summary of our efforts. In the raw data, Center and instrument (technical factors) explained a large portion of the variance. After processing, their contribution is drastically reduced, while the proportion of variance attributed to the biological Condition has increased. The "resid" (unexplained variance) is also larger, which is expected as systematic noise is removed. This confirms the success of our preprocessing pipeline.


## 3.7 Batch effects corrections

The package contains multiple methods for batch effects correction: ComBat, limma's removeBatchEffect, and their implementations in BERT (combat that allow missing values):

```{r}
```


....

Strong Lab effect has diminished, and samples now show some grouping by their biological Condition, although some batch effect remains. This demonstrates that our basic preprocessing has successfully reduced a substantial amount of technical noise.



The dendrogram also shows that samples no longer cluster strictly by their center of origin, indicating that the batch effect has been mitigated.


# Session info

```{r sessionInfo}
sessionInfo()
```
